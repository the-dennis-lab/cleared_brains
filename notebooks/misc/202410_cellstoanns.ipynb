{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0d49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import tifffile as tif\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81003bc8",
   "metadata": {},
   "source": [
    "# before this step, everything happens on the cluster\n",
    "1. first Nishan takes the raw data and makes it into a dataset.h5 and dataset.xml file compatible with BigStitcher\n",
    "2. we run CellMap_20240830.py on the dataset.h5 file. This is read, split into tiffs, and cm2 is run with these parameters below, which eventually creates \"cells_filtered.npy\"\n",
    "\n",
    "```\n",
    "  cell_detection_parameter = cells.default_cell_detection_parameter.copy();\n",
    "  cell_detection_parameter['illumination_correction'] = None;\n",
    "  cell_detection_parameter['background_correction']['shape'] = (12,12);\n",
    "  cell_detection_parameter['intensity_detection']['measure'] = ['source'];\n",
    "  cell_detection_parameter['shape_detection']['threshold'] = 100;\n",
    "  \n",
    "  io.delete_file(ws.filename('cells', postfix='maxima'))\n",
    "  cell_detection_parameter['maxima_detection']['save'] = ws.filename('cells', p>\n",
    "  sys.stdout.write('on processing param')\n",
    "  processing_parameter = cells.default_cell_detection_processing_parameter.copy>\n",
    "  processing_parameter.update(\n",
    "      processes = 40, # 'serial',\n",
    "      size_max = 100, #100, #35,\n",
    "      size_min = 30, #30,\n",
    "      overlap  = 15, #32, #10,\n",
    "      verbose = True\n",
    "      )\n",
    "      \n",
    "  thresholds = {\n",
    "      'source' : 3,\n",
    "      'size'   : (9,420)\n",
    "      }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10446847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12203987,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells = np.load('../../../../2024-02-01/cells_filtered.npy')\n",
    "np.shape(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd775fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2047\n",
      "2047\n",
      "39650\n"
     ]
    }
   ],
   "source": [
    "print(np.max(cells['x']))\n",
    "print(np.max(cells['y']))\n",
    "print(np.max(cells['z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32de0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39650"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells = pd.DataFrame(cells[['x','y','z']])\n",
    "np.max(df_cells.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf495bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on s00 len is  656904\n",
      "on s01 len is  1451126\n",
      "on s02 len is  1304171\n",
      "on s03 len is  538076\n",
      "on s04 len is  338283\n",
      "on s05 len is  794268\n",
      "on s06 len is  771246\n",
      "on s07 len is  426339\n",
      "on s08 len is  624290\n",
      "on s09 len is  685837\n",
      "on s10 len is  649258\n",
      "on s11 len is  493566\n",
      "on s12 len is  394669\n",
      "on s13 len is  626691\n",
      "on s14 len is  564342\n",
      "on s15 len is  341493\n",
      "on s16 len is  16124\n",
      "on s17 len is  725992\n",
      "on s18 len is  775465\n",
      "on s19 len is  25847\n"
     ]
    }
   ],
   "source": [
    "i=-1\n",
    "for val in np.arange(0,40000,2000):\n",
    "    #for 05-13 should be 1124 not 1999 (1125 multiples)\n",
    "    i+=1\n",
    "    sub_df=df_cells[(df_cells.z>=val)&(df_cells.z<val+2000)]\n",
    "    sub_df.z=sub_df.z-(i*2000)\n",
    "    print('on s{:02d}'.format(i),'len is ',len(sub_df))\n",
    "    sub_df.to_csv('../../../../2024-02-01/s{:02d}_cells.csv'.format(i),header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0c370",
   "metadata": {},
   "source": [
    "# then use big stitcher to run and come back to python\n",
    "\n",
    "```\n",
    "for i in {0..19}; \n",
    "do   (./transform-points --csvIn=\"../../2024-02-01/s${i}_cells.csv\" --xml='../../2024-02-01/dataset.xml' -vi=\"0,${i}\" --csvOut=\"../../2024-02-01/transformed_cells_${i}.txt\" | tail -1); \n",
    "done\n",
    "```\n",
    "each volume space is originally in - to + coordinates that are somewhat random.\n",
    "long term we should resave the xml such that the lowest point is 0,0,0\n",
    "in the mean time I manually get the points\n",
    "\n",
    "```\n",
    "./transform-points -p=0,0,0 --xml='../../2024-02-01/dataset.xml' -vi=\"0,0\"\n",
    "\n",
    "```\n",
    "\n",
    "which output\n",
    "\n",
    "```\n",
    "[-p=0,0,0, --xml=../../2024-02-01/dataset.xml, -vi=0,19]\n",
    "xml: ../../2024-02-01/dataset.xml\n",
    "Full bounding for acquisition: [-3348, -4153, -2150] -> [3361, 3984, 2052], dimensions (6710, 8138, 4203)\n",
    "Using transformations of viewId: tpId=0 setupId=19\n",
    "Applying 3d affine: 3d-affine: (0.9989147448484597, 0.0036842417426456364, -0.005586419932087294, -3336.382952430128, 0.009194227906874658, 0.9955467924508379, 0.003135422288656974, 1920.6325773574902, 0.012798322745635287, -0.003820968549952102, 2.0549030943040103, -2141.9206927840173)\n",
    "-3336.382952430128,1920.6325773574902,-2141.9206927840173\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0303be93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# now cells are in volume space - each volume is a tile\n",
    "# tile 0 is on the top right, tile 3 is the top left, tile 4 is second row far right...\n",
    "# for 2024-02 each tile is 2048,2048,1999 and there are 19 tiles\n",
    "    # the final downsampled tiff is axially sliced from the top of the brain to bottom, \n",
    "    # with cerebellum at the top of the image\n",
    "    # 560x, 679y, 351z\n",
    "\n",
    "for sval in np.arange(0,20):\n",
    "    print(sval)\n",
    "    data = pd.read_csv('../../../../2024-02-01/transformed_cells_{}.txt'.format(sval),header=None)\n",
    "    data.columns=['x','y','z']\n",
    "    # these below values are manually added based on the output from the transform_points call above & final volume size\n",
    "    # this should be automated in the future\n",
    "    xoff,yoff,zoff = [-3348, -4153, -2150]\n",
    "    xmax,ymax,zmax=[6710, 8138, 4203]\n",
    "    cmx,cmy,cmz=[560,679,351]\n",
    "\n",
    "    data.x=((data.x-xoff)*(cmx/xmax)).astype(int)\n",
    "    data.y=((data.y-yoff)*(cmy/ymax)).astype(int)\n",
    "    data.z=((data.z-zoff)*(cmz/zmax)).astype(int)\n",
    "\n",
    "    # now reformat these points for transformix\n",
    "    df=pd.DataFrame([['point','',''],[str(len(data)),'','']],columns=['x','y','z'])\n",
    "    df = pd.concat([df,data]).reset_index(drop=True)\n",
    "    df.to_csv('/home/dennislab2/Desktop/2024-02-01/2024-02-01_points_s{}.txt'.format(sval),sep=' ',header=None,index=None)\n",
    "\n",
    "    \n",
    "# for 2024-05 each tile is 2048,2048,1124 and there are 19 tiles (4 columns, 5 rows)\n",
    "    # same axial orientation as 2024-02\n",
    "    # 512, 641, 356 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac38994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform points from downsampled to allen\n",
    "# the function itself actually takes from the FIXED volume and puts in the MOVING volume,\n",
    "# so we need to align the allen (moving) to the downsampled volume (fixed)\n",
    "# one caveat: having a volume approximately 1.4x the size of the fixed is really nice, so we're\n",
    "# going to do that, but have to divide everything by 1.4 at the end to get it into proper allen space\n",
    "# ALSO I resliced Allen from sagittal to axial to match our volumes and avoid more axis swaps\n",
    "\n",
    "fx = itk.imread('../../../../brains/2024-02-01_141816_fused_12.tif',pixel_type=itk.US)\n",
    "mv = itk.imread('../../../../brains/allenCCF_25_resliced.tif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3536358",
   "metadata": {},
   "source": [
    "# you only need to make the larger volume once, make this block 'code' to do so\n",
    "reshape_vals=[]\n",
    "for i in np.arange(0,3):\n",
    "    mvshape = np.shape(mv)\n",
    "    fxshape = np.shape(fx)\n",
    "    reshape_vals.append((1.4*(fxshape[i]/mvshape[i])))\n",
    "print(reshape_vals)\n",
    "mv_140 = zoom(mv,reshape_vals,mode='nearest')\n",
    "\n",
    "tif.imsave('../../../../allen_140.tif',mv_140)\n",
    "print(np.shape(mv_140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c8bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_140= itk.imread('../../../../brains/allenCCF_25_resliced.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b1f14",
   "metadata": {},
   "source": [
    "# if you haven't already, run alignment, takes about an hour BUT you only need to do this once! \n",
    "# turn this into a code block to run\n",
    "\n",
    "\n",
    "# set the transforms\n",
    "parameter_object = itk.ParameterObject.New()\n",
    "parameter_object.AddParameterFile('/home/dennislab2/Desktop/GitHub/cleared_brains/parameter_folder/Order1_Par0000affine.txt')\n",
    "parameter_object.AddParameterFile('/home/dennislab2/Desktop/GitHub/cleared_brains/parameter_folder/Order3_Par0000bspline.txt')\n",
    "parameter_object.AddParameterFile('/home/dennislab2/Desktop/GitHub/cleared_brains/parameter_folder/Order4_Par0000bspline.txt')\n",
    "parameter_object.AddParameterFile('/home/dennislab2/Desktop/GitHub/cleared_brains/parameter_folder/Order5_Par0000bspline.txt')\n",
    "\n",
    "os.mkdir('/home/dennislab2/Desktop/allen_to_2024-02-01/')\n",
    "result_img_elx, result_transform_params = itk.elastix_registration_method(fx,mv_140,parameter_object,log_to_file=True,output_directory='/home/dennislab2/Desktop/allen_to_2024-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d10b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead we load the param files from our elastix output folder\n",
    "transform_to_apply=itk.elxParameterObjectPython.elastixParameterObject_New()\n",
    "transform_to_apply.AddParameterFile('../../../../2024-02-01/TransformParameters.0.txt')\n",
    "transform_to_apply.AddParameterFile('../../../../2024-02-01/TransformParameters.1.txt')\n",
    "transform_to_apply.AddParameterFile('../../../../2024-02-01/TransformParameters.2.txt')\n",
    "transform_to_apply.AddParameterFile('../../../../2024-02-01/TransformParameters.3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dadeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_anns = itk.imread('../../../../brains/annotation_template_25_resliced.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4f1d3bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "mxval=np.max(np.shape(mv))\n",
    "cells=np.zeros((mxval,mxval,mxval))\n",
    "for sval in np.arange(0,20):\n",
    "    print(sval)\n",
    "    transformed_coords=itk.transformix_pointset(mv,transform_to_apply,fixed_point_set_file_name='/Users/dennise/Desktop/2024-02-01/2024-02-01/2024-02-01_points_s{}.txt'.format(sval),output_directory=\"/Users/dennise/Desktop/2024-02-01\")\n",
    "    dfx=pd.DataFrame(transformed_coords)\n",
    "    dfx.columns = dfx.columns.astype(str)\n",
    "    dfx = dfx[['46','47','48']]\n",
    "    dfx.columns=['x','y','z']\n",
    "    dfx.x=dfx.x.astype(int)\n",
    "    dfx.y=dfx.y.astype(int)\n",
    "    dfx.z=dfx.z.astype(int)\n",
    "    dfx.to_csv('/Users/dennise/Desktop/2024-02-01/points_transformixed_{}.csv'.format(sval))\n",
    "    \n",
    "for sval in np.arange(0,20):   \n",
    "    for idx in dfx.index:\n",
    "        x,y,z=[dfx.x[idx],dfx.y[idx],dfx.z[idx]]\n",
    "        if (x<528) and (y<528) and (z<456):\n",
    "            cells[x,y,z]+=1\n",
    "    np.save('/Users/dennise/Desktop/2024-02-01_cells_at{}.npy'.format(sval),cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a7b5c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_arr = cells.transpose(2,1,0) # y is what x should be and x is what y should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "924bfc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 528, 456)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmax,ymax,zmax=np.shape(mv)\n",
    "rearranged_arr=rearranged_arr[0:xmax,0:ymax,0:zmax]\n",
    "print(np.shape(rearranged_arr))\n",
    "print(np.shape(mv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d3d448e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nameval='02'\n",
    "tif.imsave('/Users/dennise/Desktop/rearranged_arr_{}.tif'.format(nameval),rearranged_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0358aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.load('/Users/dennise/Desktop/emily/2024-02-01_cells_at19.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549fac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = tif.imread(\"/Users/dennise/Desktop/emily/brains/annotation_template_25_resliced_eroded.tif\")\n",
    "ann_mask = anns.copy()\n",
    "frac_vol = tif.imread('/Users/dennise/Downloads/20240514_cells.tif')\n",
    "cerebellum=[]\n",
    "df = pd.read_csv('/Users/dennise/Downloads/structure_tree_safe.csv')\n",
    "for idx in df.index:\n",
    "    if ('512' in df.structure_id_path[idx]) or ('960' in df.structure_id_path[idx]):\n",
    "        cerebellum.append(int(df.id[idx]))\n",
    "for cerebellarval in cerebellum:\n",
    "    ann_mask[ann_mask==cerebellarval]=0\n",
    "ann_mask[ann_mask>0]=1\n",
    "frac_nocerebellum=frac_vol*ann_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ced3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anncsv=pd.read_csv('/Users/dennise/Downloads/structure_tree_safe.csv',index_col=None)\n",
    "anncsv=anncsv.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a1e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_nocerebellum=frac_nocerebellum/35571273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c441fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_frac_vol = np.zeros(np.shape(frac_nocerebellum))\n",
    "valpairs=[]\n",
    "for val in np.unique(anns)[1:]:\n",
    "    sumofall=np.sum(frac_nocerebellum[anns==val])\n",
    "    if len(anncsv.safe_name[anncsv.id==val].to_list())>0:\n",
    "        valpairs.append([val,anncsv.safe_name[anncsv.id==val].to_list()[0],sumofall])\n",
    "    else:\n",
    "        valpairs.append([val,'',sumofall])\n",
    "    ann_frac_vol[anns==val]=sumofall*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9156fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals=pd.DataFrame(valpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d29662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.columns=['allen_label_no','allen_label','percentofcells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547e6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.to_csv('/Users/dennise/Desktop/20240513_annfracvol.csv')\n",
    "tif.imsave('/Users/dennise/Desktop/20240513_annfracvol.tif',ann_frac_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e2e35",
   "metadata": {},
   "source": [
    "# TODO\n",
    "in converting allen to tif from nrrd, lost precision. need to import nrrd with sitk and deal from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c182a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
